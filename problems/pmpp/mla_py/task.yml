# name: mla-py

files:
  - {"name": "submission.py", "source": "@SUBMISSION@"}
  - {"name": "task.py", "source": "task.py"}
  - {"name": "utils.py", "source": "../utils.py"}
  - {"name": "reference.py", "source": "reference.py"}
  - {"name": "eval.py", "source": "../eval.py"}

lang: "py"

description: |
  Implement mla fused attention decode function that matches the reference implementation.
  The function should handle a tuple of input tensors and apply fused attention calculation
  The shapes of all outer and inner dimensions of tensors are from DeepSeek-R1

config:
  main: "eval.py"

templates:
  Python: "../template.py"

tests:
  - {"B": 1, "S": 128, "H_Q": 128, "H_KV": 1, "D": 576, "D_V": 512, "seed":}
  - {"B": 4, "S": 1024, "H_Q": 128, "H_KV": 1, "D": 576, "D_V": 512, "seed":}

benchmarks:
  - {"B": 1, "S": 128, "H_Q": 128, "H_KV": 1, "D": 576, "D_V": 512, "seed":}
  - {"B": 4, "S": 1024, "H_Q": 128, "H_KV": 1, "D": 576, "D_V": 512, "seed":}
  
