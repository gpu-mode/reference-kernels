# name: fp16-gemm

files:
  - {"name": "submission.py", "source": "@SUBMISSION@"}
  - {"name": "task.py", "source": "task.py"}
  - {"name": "utils.py", "source": "../utils.py"}
  - {"name": "reference.py", "source": "reference.py"}
  - {"name": "eval.py", "source": "../eval.py"}

lang: "py"

description: |
  
  You will implement a fp16 matrix multiplication kernel optimized for NVIDIA B200.
  The shapes of tensors are from DeepSeek-R1.
  To be explicit, you will be given a tuple of tensors:
  ```
  (a, b, c)
  ```
  where `a` and `b` are the input matrices, and `c` is the output matrix:
  * `a` is M x K in row-major order in fp16
  * `b` is N x K in column-major order in fp16
  * `c` is M x N in row-major order in fp16
  
  Matrix sizes `M` and `N` are divisible by mma_tiler_mnk defined in the kernel, `K` is divisible by 64.

  The ranking criteria is the geometric mean of the benchmark results.

  For the grand price, your kernel will be evaluated against the speed of light analysis
  and the solution closest to the speed of light will be awarded the grand price.
  ```
  The speed of light analysis is (using 1.5Ghz clock):
   M       N       K     time[us]
  7168    128    16384    17.38
  4096    128    7168     4.34
  7168    128    2048     2.17
  ```

config:
  main: "eval.py"

templates:
  Python: "template.py"

tests:
  - {"m": 128, "n": 256, "k": 64, "seed": 1111}
  - {"m": 128, "n": 1536, "k": 7168, "seed": 1111}
  - {"m": 128, "n": 3072, "k": 1536, "seed": 1111}
  - {"m": 256, "n": 7168, "k": 256, "seed": 1111}
  - {"m": 256, "n": 7168, "k": 2048, "seed": 1111}
  - {"m": 2384, "n": 4608, "k": 7168, "seed": 1111}
  - {"m": 384, "n": 7168, "k": 2304, "seed": 1111}
  - {"m": 512, "n": 512, "k": 7168, "seed": 1111}
  - {"m": 512, "n": 4096, "k": 512, "seed": 1111}
  - {"m": 512, "n": 1536, "k": 7168, "seed": 1111}

benchmarks:
  - {"m": 7168, "n": 128, "k": 16384, "seed": 1111}
  - {"m": 4096, "n": 128, "k": 7168, "seed": 1111}
  - {"m": 7168, "n": 128, "k": 2048, "seed": 1111}

ranking_by: "geom"
